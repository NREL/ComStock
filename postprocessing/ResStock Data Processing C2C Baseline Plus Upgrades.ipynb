{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###import comstockpostproc-standard things, and then don't use most of them\n",
    "\n",
    "import os\n",
    "from textwrap import indent\n",
    "\n",
    "import boto3\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from comstockpostproc.resstock_naming_mixin_LARGEE import ResStockNamingMixin\n",
    "from comstockpostproc.units_mixin import UnitsMixin\n",
    "from comstockpostproc.s3_utilities_mixin import S3UtilitiesMixin\n",
    "from comstockpostproc import resstock_LARGEE\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResStock_data_process():\n",
    "    def __init__(self, resstock_results_folder, resstock_file_name, downselect_rows_tf, downselect_row_fields, \n",
    "                 values_to_keep,  col_plan_folder, col_plan_name,\n",
    "                 add_wide_fields_tf, dfs_for_wide_fields, wide_mergeon_fields, wide_merge_cols, wide_col_plans, wide_merge_newnames,\n",
    "                 add_local_bills_tf, downselect_cols_tf, add_long_fields_tf, rate_inputs_df, \n",
    "                 long_fields_also_wide_tf, long_fields_also_wide, long_fields_also_wide_names,\n",
    "                 save_file_tf, output_folder, output_file_name):\n",
    "        \"\"\"\n",
    "        A class to load and transform ResStock 2024.2 data for futher steps in an automated workflow\n",
    "        \"\"\"\n",
    "        #initialize members\n",
    "        self.resstock_results_folder = resstock_results_folder\n",
    "        self.resstock_file_name = resstock_file_name\n",
    "        self.downselect_rows_tf = downselect_rows_tf\n",
    "        self.downselect_row_fields = downselect_row_fields\n",
    "        self.values_to_keep = values_to_keep\n",
    "        self.col_plan_folder = col_plan_folder\n",
    "        self.col_plan_name = col_plan_name\n",
    "        self.add_wide_fields_tf = add_wide_fields_tf\n",
    "        self.dfs_for_wide_fields = dfs_for_wide_fields\n",
    "        self.wide_mergeon_fields = wide_mergeon_fields\n",
    "        self.wide_merge_cols = wide_merge_cols\n",
    "        self.wide_col_plans = wide_col_plans\n",
    "        self.wide_merge_newnames = wide_merge_newnames\n",
    "        self.add_local_bills_tf = add_local_bills_tf\n",
    "        self.downselect_cols_tf = downselect_cols_tf\n",
    "        self.add_long_fields_tf = add_long_fields_tf\n",
    "        self.rate_inputs_df = rate_inputs_df\n",
    "        self.long_fields_also_wide_tf = long_fields_also_wide_tf\n",
    "        self.long_fields_also_wide = long_fields_also_wide\n",
    "        self.long_fields_also_wide_names = long_fields_also_wide_names\n",
    "        self.save_file_tf = save_file_tf\n",
    "        self.output_folder = output_folder\n",
    "        self.output_file_name = output_file_name\n",
    "\n",
    "\n",
    "        #execute\n",
    "        self.download_data()\n",
    "        self.downselect_rows()\n",
    "        self.make_col_plan()\n",
    "        self.add_wide_fields()\n",
    "        self.downselect_cols()\n",
    "        self.pivot_data()\n",
    "        self.add_long_fields()\n",
    "        self.categorize_outputs()\n",
    "        self.addl_wide_fields_in_long()\n",
    "        self.add_weighted_values_col()\n",
    "        self.return_and_save_file()\n",
    "\n",
    "    def download_data(self):\n",
    "    #load results from already-downloaded OEDI file\n",
    "        #print (1)\n",
    "        results_file_path = os.path.join(self.resstock_results_folder, self.resstock_file_name)\n",
    "        self.data = pd.read_csv(results_file_path, engine = \"pyarrow\")\n",
    "\n",
    "    def downselect_rows(self):\n",
    "    #downselect to a subset of results \n",
    "        #print (2)\n",
    "        if(self.downselect_rows_tf == True):\n",
    "            for field, values in zip(self.downselect_row_fields, self.values_to_keep):\n",
    "                self.data = self.data.loc[self.data[field].isin(values)]\n",
    "\n",
    "    def make_col_plan(self):\n",
    "    #assign a plan for each column in the dataset, from a premade csv\n",
    "        #print (3)\n",
    "        plan_file_path = os.path.join(self.col_plan_folder, self.col_plan_name)\n",
    "        self.col_plan = pd.read_csv(plan_file_path, engine = \"pyarrow\")\n",
    "        #remove rows from column plan that refer to columns that aren't in the data\n",
    "        data_cols = self.data.columns.tolist()\n",
    "        cols_in_plan = self.col_plan['column'].tolist()\n",
    "        cols_in_plan_and_data = [x for x in cols_in_plan if x in data_cols]\n",
    "        self.col_plan = self.col_plan.loc[self.col_plan['column'].isin(cols_in_plan_and_data)].reset_index()\n",
    "        #flag columns in the data that aren't in the column plan\n",
    "        cols_not_in_plan = list(set(data_cols) - set(cols_in_plan))\n",
    "        if len(cols_not_in_plan) > 0:\n",
    "            print (\"These columns are in the data but not the column plan:\") \n",
    "            print(cols_not_in_plan)\n",
    "        #create lists of columns\n",
    "        self.cols_to_remove = self.col_plan.loc[self.col_plan['plan']=='remove', 'column'].tolist()\n",
    "        self.cols_wide = self.col_plan.loc[self.col_plan['plan']=='keep', 'column'].tolist()\n",
    "        self.cols_to_pivot = self.col_plan.loc[self.col_plan['plan']=='pivot', 'column'].tolist()\n",
    "        \n",
    "    def add_wide_fields(self):\n",
    "    #add additional wide format fields before pivoting, and also add plans for them\n",
    "        #print (4)\n",
    "        #add additional precomputed wide format fields before pivoting\n",
    "        if(self.add_wide_fields_tf == True):\n",
    "            #print (\"4a\")\n",
    "            for dfw, wide_mergeon_field, wide_merge_col, wide_merge_newname, wide_col_plan in zip(\n",
    "                self.dfs_for_wide_fields, self.wide_mergeon_fields, self.wide_merge_cols, self.wide_merge_newnames, self.wide_col_plans):\n",
    "                self.data = self.data.merge(dfw, [[wide_mergeon_field, wide_merge_col]], on = wide_mergeon_field, how = \"left\")\n",
    "                self.data.rename(columns = {wide_merge_col:wide_merge_newname}, inplace = True)\n",
    "                if self.wide_col_plan == 'pivot':\n",
    "                    self.cols_to_pivot = self.cols_to_pivot + [wide_merge_newname]\n",
    "                elif self.wide_col_plan == 'keep':\n",
    "                    self.cols_wide = self.cols_wide + [wide_merge_newname]\n",
    "                else:\n",
    "                    self.cols_to_remove = self.cols_to_remove + [wide_merge_newname]\n",
    "        #add local bills before pivoting\n",
    "        if(self.add_local_bills_tf == True):\n",
    "            #print (\"4b\")\n",
    "            for index, row in self.rate_inputs_df.iterrows():\n",
    "                self.data[row['column']] = row['fixed monthly cost']*12 + row['variable cost per kwh']*(self.data[row['col list for scaling']].sum(axis = 1))\n",
    "                if row['plan'] == 'pivot':\n",
    "                    self.cols_to_pivot = self.cols_to_pivot + [row['column']]\n",
    "                elif row['plan'] == 'keep':\n",
    "                    self.cols_wide = self.cols_wide + [row['column']]\n",
    "                else:\n",
    "                    self.cols_to_remove = self.cols_to_remove + [row['column']]\n",
    "            plan_for_new_cols_df = self.rate_inputs_df.drop(['fixed monthly cost', 'variable cost per kwh', 'col list for scaling'], axis = 1)\n",
    "            self.col_plan = pd.concat([self.col_plan, plan_for_new_cols_df], axis = 0)\n",
    "    \n",
    "    def downselect_cols(self):\n",
    "    #remove unneceessary columns\n",
    "        #print (5)\n",
    "        if(self.downselect_cols_tf == True):\n",
    "            self.data.drop(self.data[self.cols_to_remove], axis = 1, inplace = True)\n",
    "            #print(self.data.columns)\n",
    "\n",
    "    def pivot_data(self):\n",
    "    #make all the results long format, keep the characteristics wide\n",
    "        #print (6)\n",
    "        self.data_long = pd.melt(\n",
    "            self.data,\n",
    "            id_vars = self.cols_wide,\n",
    "            var_name = \"Output\",\n",
    "            value_name = \"Value\"\n",
    "        )\n",
    "    \n",
    "    def add_long_fields(self):\n",
    "    #this is where you add any long format fields.\n",
    "        #print (7)\n",
    "        if(self.add_long_fields_tf == True):\n",
    "            print('7a')\n",
    "\n",
    "    def categorize_outputs(self):\n",
    "    #Develop output categorization\n",
    "        #print (8)\n",
    "        #add units - this part isn't working for the upgrades because they have an extra part of the file name, and it isn't critical\n",
    "        #split original column name\n",
    "        #self.data_long[['out', 'Result', 'End Use', 'Type', 'Units']] = self.data_long['Output'].str.split('.', expand = True)\n",
    "        #only keep the units\n",
    "        #self.data_long.drop(self.data_long[['out', 'Result', 'End Use', 'Type']], axis = 1, inplace = True)\n",
    "        #use mappings to get the categorizations\n",
    "        out_cats = self.col_plan.drop(self.col_plan[[\"col_type\", \"plan\"]], axis = 1, inplace = False)\n",
    "        self.data_long = self.data_long.merge(out_cats, left_on = 'Output', right_on = \"column\", how = 'left')\n",
    "\n",
    "    def addl_wide_fields_in_long(self):\n",
    "    #re-merge in any long fields that are also needed as wide fields\n",
    "        #print (9)\n",
    "        if(self.long_fields_also_wide_tf == True):\n",
    "            merge_data_cols = [\"bldg_id\"] + self.long_fields_also_wide\n",
    "            self.data_long = self.data_long.merge(self.data[merge_data_cols], on = \"bldg_id\", how = \"left\")\n",
    "            for colname, newcolname in zip(self.long_fields_also_wide, self.long_fields_also_wide_names):\n",
    "                self.data_long.rename(columns = {colname:newcolname}, inplace = True)\n",
    "\n",
    "    def add_weighted_values_col(self):\n",
    "    #add a column with the weighted value alongside the unweighted value column\n",
    "        #print(10)\n",
    "        self.data_long['Weighted Value'] = self.data_long['Value']*self.data_long['weight']\n",
    "    \n",
    "    def return_and_save_file(self):\n",
    "    #save file\n",
    "        #print(11)\n",
    "        return self.data_long\n",
    "        if self.save_file_tf == True:\n",
    "            self.data_long.to_csv(os.path.join(self.output_folder, self.output_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Prepare utility rates for C2C DV\n",
    "\n",
    "##project-specific utility bills - inputs\n",
    "#Electricity\n",
    "fixed_elec_cost_monthly = 10.56\n",
    "var_elec_cost_per_kwh = 0.17404 #cf 0.137/kwh\n",
    "\n",
    "#Natural Gas\n",
    "fixed_ng_cost_monthly = 16.25\n",
    "var_ng_cost_per_ccf = 1.495\n",
    "\n",
    "#Fuel Oil\n",
    "var_fo_cost_per_gal = 2.851\n",
    "\n",
    "#Propane\n",
    "var_propane_cost_per_gal = 3.199\n",
    "\n",
    "##project-specific utility bills - unit conversions\n",
    "gal_fuel_oil_to_mbtu = 139/1000\n",
    "gal_propane_to_mbtu = 91.6 / 1000\n",
    "mbtu_to_kwh = 293.0710701722222\n",
    "dol_per_ccf_to_dol_per_therm = 1/1.038 #$ per Ccf divided by 1.038 equals $ per therm https://www.eia.gov/tools/faqs/faq.php?id=45&t=8\n",
    "therm_to_kwh = 29.307107017222222\n",
    "\n",
    "var_ng_cost_per_kwh = var_ng_cost_per_ccf * (dol_per_ccf_to_dol_per_therm) * (1/therm_to_kwh)\n",
    "var_fo_cost_per_kwh = var_fo_cost_per_gal * (1/gal_fuel_oil_to_mbtu) * (1/mbtu_to_kwh)\n",
    "var_propane_cost_per_kwh = var_propane_cost_per_gal * (1/gal_propane_to_mbtu) * (1/mbtu_to_kwh)\n",
    "\n",
    "#print(var_ng_cost_per_kwh) #0.011423113848862812, cf 0.0339307/kwh\n",
    "#print(var_fo_cost_per_kwh) #0.06998572515142275, cf 0.0704125/kwh\n",
    "#print(var_propane_cost_per_kwh) #0.11916420397790706. cf 0.101456/kWh\n",
    "\n",
    "#assemble for input\n",
    "rates_data_inputs = [\n",
    "    [\"out.bills_local.electricity.total.usd\", fixed_elec_cost_monthly, var_elec_cost_per_kwh, [\"out.electricity.total.energy_consumption.kwh\"], \"out.x\", \"pivot\", \"Utility Bills\", \"Electricity\", \"Electricity Total\", \"Total\"],\n",
    "    [\"out.bills_local.natural_gas.total.usd\", fixed_ng_cost_monthly, var_ng_cost_per_kwh, [\"out.natural_gas.total.energy_consumption.kwh\"], \"out.x\", \"pivot\", \"Utility Bills\", \"Natural Gas\", \"Natural Gas Total\", \"Total\"],\n",
    "    [\"out.bills_local.fuel_oil.total.usd\", 0, var_fo_cost_per_kwh, [\"out.fuel_oil.total.energy_consumption.kwh\"], \"out.x\", \"pivot\", \"Utility Bills\", \"Fuel Oil\", \"Fuel Oil Total\", \"Total\"],\n",
    "    [\"out.bills_local.propane.total.usd\", 0, var_propane_cost_per_kwh, [\"out.propane.total.energy_consumption.kwh\"], \"out.x\", \"pivot\", \"Utility Bills\", \"Propane\", \"Total\", \"Total\"],\n",
    "    [\"out.bills_local.all_fuels.total.usd\", 0, 1, [\"out.bills_local.electricity.total.usd\", \"out.bills_local.natural_gas.total.usd\", \"out.bills_local.fuel_oil.total.usd\", \"out.bills_local.propane.total.usd\"], \"out.x\", \"pivot\", \"Utility Bills\", \"Energy\", \"Total\", \"Total\"]\n",
    "]\n",
    "\n",
    "rate_inputs_df = pd.DataFrame(rates_data_inputs, columns = ['column', 'fixed monthly cost', 'variable cost per kwh', 'col list for scaling', 'col_type', 'plan', 'Result Type', 'Fuel', 'End Use', 'End Use Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output and save one set of data\n",
    "ResStock_data_process(\n",
    "    resstock_results_folder = \"C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Data/2024.2/AMY2018\",\n",
    "    resstock_file_name = \"PA_baseline_metadata_and_annual_results.csv\",\n",
    "    downselect_rows_tf = True, \n",
    "    downselect_row_fields = [\"in.county_name\"],\n",
    "    values_to_keep = [[\"Montgomery County\", \"Bucks County\", \"Chester County\", \"Delaware County\"]],\n",
    "    col_plan_folder = 'C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Upgrade (4.3)',\n",
    "    col_plan_name = '2024-2 Col Plan including C2C DV Upgrades.csv',\n",
    "    add_wide_fields_tf = False,\n",
    "    dfs_for_wide_fields = 'NA',\n",
    "    wide_mergeon_fields = 'NA',\n",
    "    wide_merge_cols = 'NA', \n",
    "    wide_col_plans = 'NA',\n",
    "    wide_merge_newnames = 'NA',\n",
    "    add_local_bills_tf = True,\n",
    "    downselect_cols_tf = True, \n",
    "    add_long_fields_tf = False, \n",
    "    rate_inputs_df = rate_inputs_df, \n",
    "    long_fields_also_wide_tf = True,\n",
    "    long_fields_also_wide = [\"out.emissions.all_fuels.lrmer_mid_case_15.co2e_kg\", \"out.bills_local.all_fuels.total.usd\"], \n",
    "    long_fields_also_wide_names = [\"Emissions\", \"Utility Bills Total\"],\n",
    "    save_file_tf = True,\n",
    "    output_folder = \"C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Baseline (4.2)\", \n",
    "    output_file_name = \"resstock_function_upgrades_test_1.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline\n",
      "upgrade02\n",
      "upgrade04\n"
     ]
    }
   ],
   "source": [
    "# process multiple sets of data\n",
    "up_list = [\"baseline\", \"upgrade02\", \"upgrade04\"]#, \"upgrade07\", \"upgrade09\", \"upgrade12\", \"upgrade13\", \"upgrade16\"]\n",
    "processed_data = []\n",
    "for up in up_list:\n",
    "    print (up)\n",
    "    resstock_file_name = \"PA_\" + up + \"_metadata_and_annual_results.csv\"\n",
    "    outname = \"PA_\" + up + \"processed_results.csv\"\n",
    "    results = ResStock_data_process(\n",
    "        resstock_results_folder = \"C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Data/2024.2/AMY2018\",\n",
    "        resstock_file_name = resstock_file_name,\n",
    "        downselect_rows_tf = True, \n",
    "        downselect_row_fields = [\"in.county_name\"],\n",
    "        values_to_keep = [[\"Montgomery County\", \"Bucks County\", \"Chester County\", \"Delaware County\"]],\n",
    "        col_plan_folder = 'C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Upgrade (4.3)',\n",
    "        col_plan_name = '2024-2 Col Plan including C2C DV Upgrades.csv',\n",
    "        add_wide_fields_tf = False,\n",
    "        dfs_for_wide_fields = 'NA',\n",
    "        wide_mergeon_fields = 'NA',\n",
    "        wide_merge_cols = 'NA', \n",
    "        wide_col_plans = 'NA',\n",
    "        wide_merge_newnames = 'NA',\n",
    "        add_local_bills_tf = True,\n",
    "        downselect_cols_tf = True, \n",
    "        add_long_fields_tf = False, \n",
    "        rate_inputs_df = rate_inputs_df, \n",
    "        long_fields_also_wide_tf = True,\n",
    "        long_fields_also_wide = [\"out.emissions.all_fuels.lrmer_mid_case_15.co2e_kg\", \"out.bills_local.all_fuels.total.usd\"], \n",
    "        long_fields_also_wide_names = [\"Emissions\", \"Utility Bills Total\"],\n",
    "        save_file_tf = True,\n",
    "        output_folder = \"C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Baseline (4.2)\", \n",
    "        output_file_name = outname\n",
    "        )\n",
    "    processed_data = processed_data + [results.data_long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine multiple sets of processed data into a single dataframe for saving\n",
    "# EKP 2025-01-07 this has thrown a memory error every time I've tried to run it\n",
    "processed_data_df = pd.concat(processed_data, axis = 0, copy = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save multiple sets of processed data - this is still in progress\n",
    "output_folder = \"C:/Users/epresent/NREL/BuildStock Analysis User Engagement-C2C Delaware - Documents/10_Analysis/Upgrade (4.3)\"\n",
    "output_file_name = \"C2C_DV_data_with_2ups.csv\"\n",
    "output_path = os.path.join(output_folder, output_file_name)\n",
    "processed_data_df.to_csv(output_path)\n",
    "\n",
    "#the below runs, but because the columns aren't exactly the same in every file, it isn't the way to do it\n",
    "#for dataset in processed_data:\n",
    "#    print(dataset.head())\n",
    "#    dataset.to_csv(output_path, mode = 'a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comstockpostproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
